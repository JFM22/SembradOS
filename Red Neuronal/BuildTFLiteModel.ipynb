{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Gust</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Precip.</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>43 °F</td>\n",
       "      <td>41 °F</td>\n",
       "      <td>93 °%</td>\n",
       "      <td>W</td>\n",
       "      <td>5 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1:30 AM</td>\n",
       "      <td>45 °F</td>\n",
       "      <td>41 °F</td>\n",
       "      <td>87 °%</td>\n",
       "      <td>NW</td>\n",
       "      <td>3 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2:00 AM</td>\n",
       "      <td>43 °F</td>\n",
       "      <td>41 °F</td>\n",
       "      <td>93 °%</td>\n",
       "      <td>WNW</td>\n",
       "      <td>3 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2:30 AM</td>\n",
       "      <td>45 °F</td>\n",
       "      <td>41 °F</td>\n",
       "      <td>87 °%</td>\n",
       "      <td>WNW</td>\n",
       "      <td>3 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3:00 AM</td>\n",
       "      <td>43 °F</td>\n",
       "      <td>41 °F</td>\n",
       "      <td>93 °%</td>\n",
       "      <td>WNW</td>\n",
       "      <td>6 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3:30 AM</td>\n",
       "      <td>43 °F</td>\n",
       "      <td>39 °F</td>\n",
       "      <td>87 °%</td>\n",
       "      <td>WNW</td>\n",
       "      <td>3 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>4:00 AM</td>\n",
       "      <td>41 °F</td>\n",
       "      <td>37 °F</td>\n",
       "      <td>87 °%</td>\n",
       "      <td>WNW</td>\n",
       "      <td>3 °mph</td>\n",
       "      <td>0 °mph</td>\n",
       "      <td>30.09 °in</td>\n",
       "      <td>0.0 °in</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Time Temperature Dew Point Humidity Wind Wind Speed  \\\n",
       "0  2022-01-01  1:00 AM       43 °F     41 °F    93 °%    W     5 °mph   \n",
       "1  2022-01-01  1:30 AM       45 °F     41 °F    87 °%   NW     3 °mph   \n",
       "2  2022-01-01  2:00 AM       43 °F     41 °F    93 °%  WNW     3 °mph   \n",
       "3  2022-01-01  2:30 AM       45 °F     41 °F    87 °%  WNW     3 °mph   \n",
       "4  2022-01-01  3:00 AM       43 °F     41 °F    93 °%  WNW     6 °mph   \n",
       "5  2022-01-01  3:30 AM       43 °F     39 °F    87 °%  WNW     3 °mph   \n",
       "6  2022-01-01  4:00 AM       41 °F     37 °F    87 °%  WNW     3 °mph   \n",
       "\n",
       "  Wind Gust   Pressure  Precip. Condition  \n",
       "0    0 °mph  30.09 °in  0.0 °in      Fair  \n",
       "1    0 °mph  30.09 °in  0.0 °in      Fair  \n",
       "2    0 °mph  30.09 °in  0.0 °in      Fair  \n",
       "3    0 °mph  30.09 °in  0.0 °in      Fair  \n",
       "4    0 °mph  30.09 °in  0.0 °in      Fair  \n",
       "5    0 °mph  30.09 °in  0.0 °in      Fair  \n",
       "6    0 °mph  30.09 °in  0.0 °in      Fair  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('WeatherData.csv')\n",
    "data.iloc[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fair', 'Mostly Cloudy', 'Mist', 'Fog', 'Fair / Windy',\n",
       "       'Partly Cloudy', 'Light Rain', 'Light Drizzle', 'Drizzle', 'Rain',\n",
       "       'Cloudy', 'Rain Shower', 'Heavy Rain Shower', 'Light Rain Shower',\n",
       "       'Light Rain / Windy', 'Mostly Cloudy / Windy',\n",
       "       'Partly Cloudy / Windy', 'Cloudy / Windy', 'Rain / Windy',\n",
       "       'Light Rain Shower / Windy', 'Rain Shower / Windy', 'Smoke',\n",
       "       'Heavy Rain', 'Thunder in the Vicinity', 'Thunder',\n",
       "       'Light Rain with Thunder', 'T-Storm', 'Heavy T-Storm',\n",
       "       'Heavy T-Storm / Windy', 'Patches of Fog'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = [\"Time\", \"Dew Point\", \"Wind\", \"Wind Speed\", \"Wind Gust\", \"Pressure\", \"Precip.\"])\n",
    "data[\"Temperature\"] = data[\"Temperature\"].apply( lambda x: round((int(x[:2])-32) * 5/9 + 273, 1) ) #En Kelvins\n",
    "data[\"Humidity\"] = data[\"Humidity\"].apply(lambda x: int(x[:2]))\n",
    "data['Date'] = pd.to_datetime(data['Date']) #Esto convierte la columna Date a un formato datetime, lo que permite utilizar métodos como .dt.month\n",
    "data['Month'] = data['Date'].dt.month #El método .dt.month extrae el número del mes de la fecha.\n",
    "data = data.drop(columns = [\"Date\"])\n",
    "labels = data.Condition.unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javic\\AppData\\Local\\Temp\\ipykernel_31668\\1567509972.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  processed_data[\"NoRain\"].loc[data.Condition.isin(norain)] = 1\n",
      "C:\\Users\\javic\\AppData\\Local\\Temp\\ipykernel_31668\\1567509972.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_data[\"NoRain\"].loc[data.Condition.isin(norain)] = 1\n",
      "C:\\Users\\javic\\AppData\\Local\\Temp\\ipykernel_31668\\1567509972.py:20: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  processed_data[\"MightRain\"].loc[data.Condition.isin(mightrain)] = 1\n",
      "C:\\Users\\javic\\AppData\\Local\\Temp\\ipykernel_31668\\1567509972.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_data[\"MightRain\"].loc[data.Condition.isin(mightrain)] = 1\n",
      "C:\\Users\\javic\\AppData\\Local\\Temp\\ipykernel_31668\\1567509972.py:22: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  processed_data[\"Rain\"].loc[data.Condition.isin(rain)] = 1\n",
      "C:\\Users\\javic\\AppData\\Local\\Temp\\ipykernel_31668\\1567509972.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_data[\"Rain\"].loc[data.Condition.isin(rain)] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Month</th>\n",
       "      <th>NoRain</th>\n",
       "      <th>MightRain</th>\n",
       "      <th>Rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279.1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280.2</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279.1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280.2</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>279.1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33239</th>\n",
       "      <td>280.8</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33240</th>\n",
       "      <td>280.2</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33241</th>\n",
       "      <td>280.2</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33242</th>\n",
       "      <td>279.1</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33243</th>\n",
       "      <td>279.1</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33244 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature  Humidity  Month  NoRain  MightRain  Rain\n",
       "0            279.1        93      1       1          0     0\n",
       "1            280.2        87      1       1          0     0\n",
       "2            279.1        93      1       1          0     0\n",
       "3            280.2        87      1       1          0     0\n",
       "4            279.1        93      1       1          0     0\n",
       "...            ...       ...    ...     ...        ...   ...\n",
       "33239        280.8        66      1       1          0     0\n",
       "33240        280.2        71      1       1          0     0\n",
       "33241        280.2        71      1       1          0     0\n",
       "33242        279.1        70      1       1          0     0\n",
       "33243        279.1        70      1       1          0     0\n",
       "\n",
       "[33244 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = data.copy()\n",
    "\n",
    "# norain = ['Mostly Cloudy', 'Fair', 'Partly Cloudy', 'Haze', 'Fog', 'Mostly Cloudy / Windy', 'Cloudy', 'Partly Cloudy / Windy']\n",
    "# mightrain = ['Showers in the Vicinity', 'Thunder in the Vicinity', 'Thunder']\n",
    "# light_rain =  ['Light Rain Shower', 'Light Rain', 'Light Rain / Windy']\n",
    "# rain = ['Rain Shower', 'Rain', 'Heavy Rain', 'Heavy Rain Shower']\n",
    "# storm = ['Light Rain with Thunder', 'Heavy T-Storm', 'T-Storm']\n",
    "norain = ['Mostly Cloudy', 'Fair', 'Partly Cloudy', 'Haze', 'Fog', 'Mostly Cloudy / Windy', 'Cloudy', 'Partly Cloudy / Windy']\n",
    "mightrain = ['Showers in the Vicinity', 'Thunder in the Vicinity', 'Thunder']\n",
    "rain = ['Rain Shower', 'Light Rain Shower', 'Light Rain', 'Rain', 'Heavy Rain', 'Light Rain with Thunder', 'Heavy Rain Shower', 'Heavy T-Storm', 'T-Storm', 'Light Rain / Windy']\n",
    "\n",
    "\n",
    "processed_data[\"NoRain\"] = 0\n",
    "processed_data[\"MightRain\"] = 0\n",
    "# processed_data[\"LightRain\"] = 0\n",
    "processed_data[\"Rain\"] = 0\n",
    "# processed_data[\"Storm\"] = 0\n",
    "\n",
    "processed_data[\"NoRain\"].loc[data.Condition.isin(norain)] = 1\n",
    "processed_data[\"MightRain\"].loc[data.Condition.isin(mightrain)] = 1\n",
    "# processed_data[\"LightRain\"].loc[data.Condition.isin(light_rain)] = 1\n",
    "processed_data[\"Rain\"].loc[data.Condition.isin(rain)] = 1\n",
    "# processed_data[\"Storm\"].loc[data.Condition.isin(storm)] = 1\n",
    "processed_data = processed_data.drop(columns=\"Condition\")\n",
    "\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33237, 18), (33237, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = processed_data[[\"NoRain\", \"MightRain\",\"LightRain\", \"Rain\", \"Storm\"]].to_numpy()[7:]\n",
    "# rawx = processed_data.drop(columns = [\"NoRain\", \"MightRain\",\"LightRain\", \"Rain\", \"Storm\"]).to_numpy()\n",
    "y = processed_data[[\"NoRain\", \"MightRain\", \"Rain\"]].to_numpy()[7:]\n",
    "rawx = processed_data.drop(columns = [\"NoRain\", \"MightRain\", \"Rain\"]).to_numpy()\n",
    "x = []\n",
    "temp = np.array(0)\n",
    "for i in range(len(rawx)-7):\n",
    "    temp = rawx[i:i+6].flatten()\n",
    "    #print(temp)\n",
    "    x.append(temp)\n",
    "x = np.array(x)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280.2  87.    1.  279.1  93.    1.  280.2  87.    1.  279.1  93.    1.\n",
      " 279.1  87.    1.  278.   87.    1. ]\n",
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x[1])\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.20, random_state=33, stratify=y)\n",
    "#Para asegurar que haya datos de prueba para todas las clases al usar train_test_split de scikit-learn, debes hacer que la partición sea estratificada según las clases de la variable objetivo y. Esto se logra utilizando el parámetro stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 25.9448 - val_accuracy: 0.9650 - val_loss: 4.6334\n",
      "Epoch 2/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7372 - loss: 15.2496 - val_accuracy: 0.9650 - val_loss: 3.9761\n",
      "Epoch 3/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7869 - loss: 10.0742 - val_accuracy: 0.9650 - val_loss: 3.1318\n",
      "Epoch 4/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.8094 - loss: 7.0799 - val_accuracy: 0.9650 - val_loss: 2.3041\n",
      "Epoch 5/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.8278 - loss: 4.9000 - val_accuracy: 0.9650 - val_loss: 1.5485\n",
      "Epoch 6/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.8386 - loss: 3.2131 - val_accuracy: 0.9650 - val_loss: 0.9636\n",
      "Epoch 7/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.8484 - loss: 2.1877 - val_accuracy: 0.9646 - val_loss: 0.4529\n",
      "Epoch 8/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.8635 - loss: 1.1741 - val_accuracy: 0.9646 - val_loss: 0.2007\n",
      "Epoch 9/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8941 - loss: 0.6928 - val_accuracy: 0.9643 - val_loss: 0.1594\n",
      "Epoch 10/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9009 - loss: 0.6027 - val_accuracy: 0.9635 - val_loss: 0.1673\n",
      "Epoch 11/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9028 - loss: 0.5512 - val_accuracy: 0.9643 - val_loss: 0.1742\n",
      "Epoch 12/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9193 - loss: 0.5030 - val_accuracy: 0.9639 - val_loss: 0.1864\n",
      "Epoch 13/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9247 - loss: 0.5086 - val_accuracy: 0.9631 - val_loss: 0.1974\n",
      "Epoch 14/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9245 - loss: 0.4545 - val_accuracy: 0.9635 - val_loss: 0.1953\n",
      "Epoch 15/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9299 - loss: 0.4558 - val_accuracy: 0.9646 - val_loss: 0.1921\n",
      "Epoch 16/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9308 - loss: 0.4647 - val_accuracy: 0.9635 - val_loss: 0.2068\n",
      "Epoch 17/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9349 - loss: 0.4451 - val_accuracy: 0.9643 - val_loss: 0.1961\n",
      "Epoch 18/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9365 - loss: 0.4415 - val_accuracy: 0.9646 - val_loss: 0.2004\n",
      "Epoch 19/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9460 - loss: 0.4202 - val_accuracy: 0.9635 - val_loss: 0.1973\n",
      "Epoch 20/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9488 - loss: 0.3862 - val_accuracy: 0.9650 - val_loss: 0.1936\n",
      "Epoch 21/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9545 - loss: 0.3977 - val_accuracy: 0.9650 - val_loss: 0.1825\n",
      "Epoch 22/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9566 - loss: 0.3835 - val_accuracy: 0.9650 - val_loss: 0.1776\n",
      "Epoch 23/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9571 - loss: 0.3735 - val_accuracy: 0.9650 - val_loss: 0.1700\n",
      "Epoch 24/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9565 - loss: 0.3747 - val_accuracy: 0.9650 - val_loss: 0.1643\n",
      "Epoch 25/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9590 - loss: 0.3577 - val_accuracy: 0.9650 - val_loss: 0.1685\n",
      "Epoch 26/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9574 - loss: 0.3645 - val_accuracy: 0.9650 - val_loss: 0.1676\n",
      "Epoch 27/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.3544 - val_accuracy: 0.9646 - val_loss: 0.1792\n",
      "Epoch 28/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9611 - loss: 0.3337 - val_accuracy: 0.9650 - val_loss: 0.1950\n",
      "Epoch 29/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9581 - loss: 0.3585 - val_accuracy: 0.9650 - val_loss: 0.1771\n",
      "Epoch 30/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9610 - loss: 0.3502 - val_accuracy: 0.9650 - val_loss: 0.1852\n",
      "Epoch 31/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9601 - loss: 0.3370 - val_accuracy: 0.9650 - val_loss: 0.1984\n",
      "Epoch 32/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9582 - loss: 0.3559 - val_accuracy: 0.9650 - val_loss: 0.1887\n",
      "Epoch 33/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9599 - loss: 0.3267 - val_accuracy: 0.9650 - val_loss: 0.1840\n",
      "Epoch 34/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9601 - loss: 0.3282 - val_accuracy: 0.9650 - val_loss: 0.1872\n",
      "Epoch 35/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9598 - loss: 0.3092 - val_accuracy: 0.9650 - val_loss: 0.2214\n",
      "Epoch 36/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9608 - loss: 0.2980 - val_accuracy: 0.9650 - val_loss: 0.2245\n",
      "Epoch 37/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9609 - loss: 0.2914 - val_accuracy: 0.9650 - val_loss: 0.2435\n",
      "Epoch 38/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9591 - loss: 0.2889 - val_accuracy: 0.9650 - val_loss: 0.2060\n",
      "Epoch 39/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.9604 - loss: 0.2946 - val_accuracy: 0.9650 - val_loss: 0.2052\n",
      "Epoch 40/40\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9618 - loss: 0.2743 - val_accuracy: 0.9650 - val_loss: 0.2194\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9606 - loss: 0.2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(14, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=40, validation_split=0.1, batch_size=128)\n",
    "\n",
    "test_results = model.evaluate(xtest, ytest, verbose=1)\n",
    "\n",
    "model.export('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"model/\") # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header file, model.h, is 3,728 bytes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"model.tflite\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Predicciones: [0]\n"
     ]
    }
   ],
   "source": [
    "x_new = np.array([\n",
    "    [285, 88, 3, 285, 88, 3, 285, 88, 3, 285, 88, 3, 285, 88, 3, 285, 88, 3],\n",
    "    # Aquí añade más muestras de prueba si lo deseas\n",
    "])\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions = model.predict(x_new)\n",
    "\n",
    "# Obtener las clases predichas (índice del valor más alto en las predicciones)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Predicciones:\", predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
